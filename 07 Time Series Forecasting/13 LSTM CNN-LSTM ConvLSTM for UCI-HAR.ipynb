{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape:(7352, 128, 9),train_y.shape:(7352, 6)\n",
      "\n",
      "test_X.shape:(2947, 128, 9),test_y.shape:(2947, 6)\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#1: 90.770\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#2: 90.804\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#3: 88.768\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#4: 88.870\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#5: 90.227\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#6: 87.615\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#7: 91.313\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#8: 87.479\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">#9: 91.144\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 100)               44000     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 54,706\n",
      "Trainable params: 54,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      ">#10: 90.092\n",
      "Accuracy: 89.708% (+/-1.354)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "def load_dataset(data_rootdir, dirname, group):\n",
    "    '''\n",
    "    该函数实现将训练数据或测试数据文件列表堆叠为三维数组\n",
    "    '''\n",
    "    filename_list = []\n",
    "    filepath_list = []\n",
    "    X = []\n",
    "    \n",
    "    # os.walk() 方法是一个简单易用的文件、目录遍历器，可以高效的处理文件、目录。\n",
    "    for rootdir, dirnames, filenames in os.walk(data_rootdir + dirname):\n",
    "        for filename in filenames:\n",
    "            filename_list.append(filename)\n",
    "            filepath_list.append(os.path.join(rootdir, filename))\n",
    "        #print(filename_list)\n",
    "        #print(filepath_list)\n",
    "    \n",
    "    # 遍历根目录下的文件，并读取为DataFrame格式；\n",
    "    for filepath in filepath_list:\n",
    "        X.append(load_file(filepath))\n",
    "    \n",
    "    X = np.dstack(X) # dstack沿第三个维度叠加，两个二维数组叠加后，前两个维度尺寸不变，第三个维度增加；\n",
    "    y = load_file(data_rootdir+'/y_'+group+'.txt')\n",
    "    # one-hot编码。这个之前的文章中提到了，因为原数据集标签从1开始，而one-hot编码从0开始，所以要先减去1\n",
    "    y = to_categorical(y-1)\n",
    "    print('{}_X.shape:{},{}_y.shape:{}\\n'.format(group,X.shape,group,y.shape))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 15, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "        \n",
    "\n",
    "def run_experiment(trainX, trainy, testX, testy, repeats=10):\n",
    "\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    \n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dir = 'D:/GraduationCode/01 Datasets/UCI HAR Dataset/train/'\n",
    "    test_dir = 'D:/GraduationCode/01 Datasets/UCI HAR Dataset/test/'\n",
    "    dirname = '/Inertial Signals/'\n",
    "    trainX, trainy = load_dataset(train_dir, dirname, 'train')\n",
    "    testX, testy = load_dataset(test_dir, dirname, 'test')\n",
    "\n",
    "    run_experiment(trainX, trainy, testX, testy, repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape:(7352, 128, 9),train_y.shape:(7352, 6)\n",
      "\n",
      "test_X.shape:(2947, 128, 9),test_y.shape:(2947, 6)\n",
      "\n",
      ">#1: 90.126\n",
      ">#2: 90.872\n",
      "Accuracy: 90.499% (+/-0.373)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, ConvLSTM2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "def load_dataset(data_rootdir, dirname, group):\n",
    "    '''\n",
    "    该函数实现将训练数据或测试数据文件列表堆叠为三维数组\n",
    "    '''\n",
    "    filename_list = []\n",
    "    filepath_list = []\n",
    "    X = []\n",
    "    \n",
    "    # os.walk() 方法是一个简单易用的文件、目录遍历器，可以高效的处理文件、目录。\n",
    "    for rootdir, dirnames, filenames in os.walk(data_rootdir + dirname):\n",
    "        for filename in filenames:\n",
    "            filename_list.append(filename)\n",
    "            filepath_list.append(os.path.join(rootdir, filename))\n",
    "        #print(filename_list)\n",
    "        #print(filepath_list)\n",
    "    \n",
    "    # 遍历根目录下的文件，并读取为DataFrame格式；\n",
    "    for filepath in filepath_list:\n",
    "        X.append(load_file(filepath))\n",
    "    \n",
    "    X = np.dstack(X) # dstack沿第三个维度叠加，两个二维数组叠加后，前两个维度尺寸不变，第三个维度增加；\n",
    "    y = load_file(data_rootdir+'/y_'+group+'.txt')\n",
    "    # one-hot编码。这个之前的文章中提到了，因为原数据集标签从1开始，而one-hot编码从0开始，所以要先减去1\n",
    "    y = to_categorical(y-1)\n",
    "    print('{}_X.shape:{},{}_y.shape:{}\\n'.format(group,X.shape,group,y.shape))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 25, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    n_steps, n_length = 4, 32\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), \n",
    "                              input_shape=(None, n_length, n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "        \n",
    "\n",
    "def run_experiment(trainX, trainy, testX, testy, repeats=10):\n",
    "\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    \n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dir = 'D:/GraduationCode/01 Datasets/UCI HAR Dataset/train/'\n",
    "    test_dir = 'D:/GraduationCode/01 Datasets/UCI HAR Dataset/test/'\n",
    "    dirname = '/Inertial Signals/'\n",
    "    trainX, trainy = load_dataset(train_dir, dirname, 'train')\n",
    "    testX, testy = load_dataset(test_dir, dirname, 'test')\n",
    "\n",
    "    run_experiment(trainX, trainy, testX, testy, repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape:(7352, 128, 9),train_y.shape:(7352, 6)\n",
      "\n",
      "test_X.shape:(2947, 128, 9),test_y.shape:(2947, 6)\n",
      "\n",
      ">#1: 90.159\n",
      ">#2: 91.347\n",
      "Accuracy: 90.753% (+/-0.594)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM, TimeDistributed, ConvLSTM2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "def load_dataset(data_rootdir, dirname, group):\n",
    "    '''\n",
    "    该函数实现将训练数据或测试数据文件列表堆叠为三维数组\n",
    "    '''\n",
    "    filename_list = []\n",
    "    filepath_list = []\n",
    "    X = []\n",
    "    \n",
    "    # os.walk() 方法是一个简单易用的文件、目录遍历器，可以高效的处理文件、目录。\n",
    "    for rootdir, dirnames, filenames in os.walk(data_rootdir + dirname):\n",
    "        for filename in filenames:\n",
    "            filename_list.append(filename)\n",
    "            filepath_list.append(os.path.join(rootdir, filename))\n",
    "        #print(filename_list)\n",
    "        #print(filepath_list)\n",
    "    \n",
    "    # 遍历根目录下的文件，并读取为DataFrame格式；\n",
    "    for filepath in filepath_list:\n",
    "        X.append(load_file(filepath))\n",
    "    \n",
    "    X = np.dstack(X) # dstack沿第三个维度叠加，两个二维数组叠加后，前两个维度尺寸不变，第三个维度增加；\n",
    "    y = load_file(data_rootdir+'/y_'+group+'.txt')\n",
    "    # one-hot编码。这个之前的文章中提到了，因为原数据集标签从1开始，而one-hot编码从0开始，所以要先减去1\n",
    "    y = to_categorical(y-1)\n",
    "    print('{}_X.shape:{},{}_y.shape:{}\\n'.format(group,X.shape,group,y.shape))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 25, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "\n",
    "    n_steps, n_length = 4, 32\n",
    "\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "        \n",
    "\n",
    "def run_experiment(trainX, trainy, testX, testy, repeats=10):\n",
    "\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    \n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dir = 'D:/GraduationCode/01 Datasets/UCI HAR Dataset/train/'\n",
    "    test_dir = 'D:/GraduationCode/01 Datasets/UCI HAR Dataset/test/'\n",
    "    dirname = '/Inertial Signals/'\n",
    "    trainX, trainy = load_dataset(train_dir, dirname, 'train')\n",
    "    testX, testy = load_dataset(test_dir, dirname, 'test')\n",
    "\n",
    "    run_experiment(trainX, trainy, testX, testy, repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
