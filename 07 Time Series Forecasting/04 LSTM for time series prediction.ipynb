{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D, TimeDistributed, MaxPooling1D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "\n",
    "class UnivariateModels:\n",
    "    '''\n",
    "    单变量时间序列LSTM模型\n",
    "    '''\n",
    "    def __init__(self, sequence, test_seq, n_seq, n_steps, sw_width, features, epochs_num, verbose_set, flag): \n",
    "        self.sequence = sequence\n",
    "        self.test_seq = test_seq\n",
    "        self.sw_width = sw_width\n",
    "        self.features = features\n",
    "        self.epochs_num = epochs_num\n",
    "        self.verbose_set = verbose_set\n",
    "        self.flag = flag\n",
    "        self.X, self.y = [], []\n",
    "        \n",
    "        self.n_seq = n_seq\n",
    "        self.n_steps = n_steps       \n",
    "        \n",
    "    def split_sequence(self):\n",
    "        for i in range(len(self.sequence)):\n",
    "            # 找到最后一个元素的索引\n",
    "            end_index = i + self.sw_width\n",
    "            # 如果最后一个滑动窗口中的最后一个元素的索引大于序列中最后一个元素的索引则丢弃该样本\n",
    "            if end_index > len(self.sequence) - 1:\n",
    "                break\n",
    "                \n",
    "            # 实现以滑动步长为1（因为是for循环），窗口宽度为self.sw_width的滑动步长取值\n",
    "            seq_x, seq_y = self.sequence[i:end_index], self.sequence[end_index]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            \n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "    \n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "        \n",
    "        if self.flag == 1:\n",
    "            self.X = self.X.reshape((self.X.shape[0], self.n_seq, self.n_steps, self.features))\n",
    "        elif self.flag == 2:\n",
    "            self.X = self.X.reshape((self.X.shape[0], self.n_seq, 1, self.n_steps, self.features))\n",
    "        else:\n",
    "            self.X = self.X.reshape((self.X.shape[0], self.X.shape[1], self.features))\n",
    "        \n",
    "        print('X:\\n{}\\ny:\\n{}\\n'.format(self.X, self.y))\n",
    "        print('X.shape:{}, y.shape:{}\\n'.format(self.X.shape, self.y.shape))\n",
    "        return self.X, self.y\n",
    "    \n",
    "    def vanilla_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(self.sw_width, self.features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        \n",
    "#         model = Sequential()\n",
    "#         model.add(LSTM(50, activation='relu', input_shape=(self.sw_width, self.features),\n",
    "#                        # 其它参数配置\n",
    "#                        recurrent_activation='sigmoid', use_bias=True, kernel_initializer='glorot_uniform', \n",
    "#                        recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
    "#                        recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, \n",
    "#                        bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=2))\n",
    "        \n",
    "#         model.add(Dense(units=1,\n",
    "#                         # 其它参数配置\n",
    "#                         activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "#                         kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None))\n",
    "        \n",
    "#         model.compile(optimizer='adam', loss='mse', \n",
    "#                       # 其它参数配置\n",
    "#                       metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "#         print(model.summary())\n",
    "        \n",
    "#         history = model.fit(self.X, self.y, self.epochs_num, self.verbose_set, \n",
    "#                   # 其它参数配置\n",
    "#                   callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, \n",
    "#                   initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "                \n",
    "#         model.predict(self.test_seq, verbose=self.verbose_set,\n",
    "#                       # 其它参数配置\n",
    "#                       steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "\n",
    "    def stacked_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', return_sequences=True, \n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        \n",
    "    def bidirectional_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(50, activation='relu'), \n",
    "                                input_shape=(self.sw_width, self.features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        \n",
    "    def cnn_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
    "                                  input_shape=(None, self.n_steps, self.features)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(50, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "    \n",
    "    def conv_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu',\n",
    "                            input_shape=(self.n_seq, 1, self.n_steps, self.features)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30] 40\n",
      "[20 30 40] 50\n",
      "[30 40 50] 60\n",
      "[40 50 60] 70\n",
      "[50 60 70] 80\n",
      "[60 70 80] 90\n",
      "X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]\n",
      "\n",
      " [[60]\n",
      "  [70]\n",
      "  [80]]]\n",
      "y:\n",
      "[40 50 60 70 80 90]\n",
      "\n",
      "X.shape:(6, 3, 1), y.shape:(6,)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:603.0445827874324\n",
      "yhat:[[100.85666]] \n",
      "-----------------------------\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:337.3305027484894\n",
      "yhat:[[102.78299]] \n",
      "-----------------------------\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:283.14844233221066\n",
      "yhat:[[100.81099]] \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    single_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    sw_width = 3\n",
    "    features = 1\n",
    "    \n",
    "    n_seq = 2\n",
    "    n_steps = 2\n",
    "    epochs = 300\n",
    "    verbose = 0\n",
    "    \n",
    "    test_seq = np.array([70, 80, 90])\n",
    "    test_seq = test_seq.reshape((1, sw_width, features))\n",
    "    \n",
    "    UnivariateLSTM = UnivariateModels(single_seq, test_seq, n_seq, n_steps, sw_width, features, epochs, verbose, flag=0)\n",
    "    UnivariateLSTM.split_sequence()\n",
    "    UnivariateLSTM.vanilla_lstm()\n",
    "    UnivariateLSTM.stacked_lstm()\n",
    "    UnivariateLSTM.bidirectional_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40] 50\n",
      "[20 30 40 50] 60\n",
      "[30 40 50 60] 70\n",
      "[40 50 60 70] 80\n",
      "[50 60 70 80] 90\n",
      "X:\n",
      "[[[[10]\n",
      "   [20]]\n",
      "\n",
      "  [[30]\n",
      "   [40]]]\n",
      "\n",
      "\n",
      " [[[20]\n",
      "   [30]]\n",
      "\n",
      "  [[40]\n",
      "   [50]]]\n",
      "\n",
      "\n",
      " [[[30]\n",
      "   [40]]\n",
      "\n",
      "  [[50]\n",
      "   [60]]]\n",
      "\n",
      "\n",
      " [[[40]\n",
      "   [50]]\n",
      "\n",
      "  [[60]\n",
      "   [70]]]\n",
      "\n",
      "\n",
      " [[[50]\n",
      "   [60]]\n",
      "\n",
      "  [[70]\n",
      "   [80]]]]\n",
      "y:\n",
      "[50 60 70 80 90]\n",
      "\n",
      "X.shape:(5, 2, 2, 1), y.shape:(5,)\n",
      "\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:96.9693284504041\n",
      "yhat:[[100.737885]] \n",
      "-----------------------------\n",
      "[10 20 30 40] 50\n",
      "[20 30 40 50] 60\n",
      "[30 40 50 60] 70\n",
      "[40 50 60 70] 80\n",
      "[50 60 70 80] 90\n",
      "X:\n",
      "[[[[[10]\n",
      "    [20]]]\n",
      "\n",
      "\n",
      "  [[[30]\n",
      "    [40]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[20]\n",
      "    [30]]]\n",
      "\n",
      "\n",
      "  [[[40]\n",
      "    [50]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[30]\n",
      "    [40]]]\n",
      "\n",
      "\n",
      "  [[[50]\n",
      "    [60]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[40]\n",
      "    [50]]]\n",
      "\n",
      "\n",
      "  [[[60]\n",
      "    [70]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[50]\n",
      "    [60]]]\n",
      "\n",
      "\n",
      "  [[[70]\n",
      "    [80]]]]]\n",
      "y:\n",
      "[50 60 70 80 90]\n",
      "\n",
      "X.shape:(5, 2, 1, 2, 1), y.shape:(5,)\n",
      "\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:236.70842473191\n",
      "yhat:[[103.98932]] \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    single_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    sw_width = 4\n",
    "    features = 1\n",
    "    \n",
    "    n_seq = 2\n",
    "    n_steps = 2\n",
    "    epochs = 500\n",
    "    verbose = 0\n",
    "    \n",
    "    test_seq = np.array([60, 70, 80, 90])\n",
    "    test_seq = test_seq.reshape((1, n_seq, n_steps, features))\n",
    "    \n",
    "    UnivariateLSTM = UnivariateModels(single_seq, test_seq, n_seq, n_steps, sw_width, features, epochs, verbose, flag=1)\n",
    "    UnivariateLSTM.split_sequence()\n",
    "    UnivariateLSTM.cnn_lstm()\n",
    "    \n",
    "    test_seq = test_seq.reshape((1, n_seq, 1, n_steps, features))\n",
    "    UnivariateLSTM = UnivariateModels(single_seq, test_seq, n_seq, n_steps, sw_width, features, epochs, verbose, flag=2)\n",
    "    UnivariateLSTM.split_sequence()\n",
    "    UnivariateLSTM.conv_lstm()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_ = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "x_input_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten\n",
    "\n",
    "def mock_seq(seq1, seq2):\n",
    "    '''\n",
    "    构造虚拟序列数据\n",
    "    实现将多个单列序列数据构造成类似于实际数据的列表的格式\n",
    "    '''\n",
    "    seq1 = np.array(seq1)\n",
    "    seq2 = np.array(seq2)\n",
    "    seq3 = np.array([seq1[i]+seq2[i] for i in range(len(seq1))])\n",
    "    \n",
    "    seq1 = seq1.reshape((len(seq1), 1))\n",
    "    seq2 = seq2.reshape((len(seq2), 1))\n",
    "    seq3 = seq3.reshape((len(seq3), 1))\n",
    "    \n",
    "    # 对于二维数组，沿第二个维度堆叠，相当于列数增加；可以想象成往书架里一本一本的摆书\n",
    "    dataset = np.hstack((seq1, seq2, seq3))\n",
    "    \n",
    "    return dataset\n",
    "        \n",
    "    \n",
    "class MultiInputModels:\n",
    "    '''\n",
    "    单变量时间序列LSTM模型\n",
    "    '''\n",
    "    def __init__(self, train_seq, test_seq, sw_width, epochs_num, verbose_set): \n",
    "        '''\n",
    "        初始化变量和参数\n",
    "        '''\n",
    "        self.train_seq = train_seq\n",
    "        self.test_seq = test_seq\n",
    "        self.sw_width = sw_width\n",
    "        \n",
    "        self.epochs_num = epochs_num\n",
    "        self.verbose_set = verbose_set\n",
    "        \n",
    "        self.X, self.y = [], []     \n",
    "        \n",
    "    def split_sequence_multi_input(self):\n",
    "        '''\n",
    "        该函数实现多输入序列数据的样本划分\n",
    "        '''\n",
    "        for i in range(len(self.train_seq)):\n",
    "            # 找到最后一个元素的索引，因为for循环中i从1开始，切片索引从0开始，切片区间前闭后开，所以不用减去1；\n",
    "            end_index = i + self.sw_width\n",
    "            # 如果最后一个滑动窗口中的最后一个元素的索引大于序列中最后一个元素的索引则丢弃该样本；\n",
    "            # 这里len(self.sequence)没有减去1的原因是：保证最后一个元素的索引恰好等于序列数据索引时，能够截取到样本；\n",
    "            if end_index > len(self.train_seq) :\n",
    "                break\n",
    "                \n",
    "            # 实现以滑动步长为1（因为是for循环），窗口宽度为self.sw_width的滑动步长取值；\n",
    "            # [i:end_index, :-1] 截取第i行到第end_index-1行、除最后一列之外的列的数据；\n",
    "            # [end_index-1, -1] 截取第end_index-1行、最后一列的单个数据，其实是在截取期望预测值y；\n",
    "            seq_x, seq_y = self.train_seq[i:end_index, :-1], self.train_seq[end_index-1, -1]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            \n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "        self.features = self.X.shape[2]\n",
    "        self.test_seq = self.test_seq.reshape((1, self.sw_width, self.test_seq.shape[1]))\n",
    "\n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "        \n",
    "        print('X:\\n{}\\ny:\\n{}\\ntest_seq:\\n{}\\n'.format(self.X, self.y, self.test_seq))\n",
    "        print('X.shape:{}, y.shape:{}, test_seq.shape:{}\\n'.format(self.X.shape, self.y.shape, self.test_seq.shape))\n",
    "        \n",
    "        return self.X, self.y, self.features, self.test_seq\n",
    "    \n",
    "    def split_sequence_parallel(self):\n",
    "        '''\n",
    "        该函数实现多输入序列数据的样本划分\n",
    "        '''\n",
    "        for i in range(len(self.train_seq)):\n",
    "            # 找到最后一个元素的索引，因为for循环中i从1开始，切片索引从0开始，切片区间前闭后开，所以不用减去1；\n",
    "            end_index = i + self.sw_width\n",
    "            # 如果最后一个滑动窗口中的最后一个元素的索引大于序列中最后一个元素的索引则丢弃该样本；\n",
    "            # 这里len(self.sequence)减去1的原因是：保证最后一个元素的索引恰好等于序列数据索引时，能够截取到样本；\n",
    "            if end_index > len(self.train_seq) - 1:\n",
    "                break\n",
    "                \n",
    "            # 实现以滑动步长为1（因为是for循环），窗口宽度为self.sw_width的滑动步长取值；\n",
    "            # [i:end_index, :] 截取第i行到第end_index-1行、所有列的数据；\n",
    "            # [end_index-1, :] 截取第end_index行、所有列的数据；\n",
    "            seq_x, seq_y = self.train_seq[i:end_index, :], self.train_seq[end_index, :]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            \n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "        self.features = self.X.shape[2]\n",
    "        self.test_seq = self.test_seq.reshape((1, self.sw_width, self.test_seq.shape[1]))\n",
    "\n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "        \n",
    "        print('X:\\n{}\\ny:\\n{}\\ntest_seq:\\n{}\\n'.format(self.X, self.y, self.test_seq))\n",
    "        print('X.shape:{}, y.shape:{}, test_seq.shape:{}\\n'.format(self.X.shape, self.y.shape, self.test_seq.shape))\n",
    "        \n",
    "        return self.X, self.y, self.features, self.test_seq    \n",
    "    \n",
    "    def vanilla_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', \n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        \n",
    "    def stacked_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, activation='relu', return_sequences=True, \n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(LSTM(100, activation='relu'))\n",
    "        model.add(Dense(self.features))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------以下为 【多输入序列LSTM模型】 相关信息-----------------\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] 65\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] 85\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] 105\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] 125\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] 145\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] 165\n",
      "[[70 75]\n",
      " [80 85]\n",
      " [90 95]] 185\n",
      "X:\n",
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]\n",
      "\n",
      " [[20 25]\n",
      "  [30 35]\n",
      "  [40 45]]\n",
      "\n",
      " [[30 35]\n",
      "  [40 45]\n",
      "  [50 55]]\n",
      "\n",
      " [[40 45]\n",
      "  [50 55]\n",
      "  [60 65]]\n",
      "\n",
      " [[50 55]\n",
      "  [60 65]\n",
      "  [70 75]]\n",
      "\n",
      " [[60 65]\n",
      "  [70 75]\n",
      "  [80 85]]\n",
      "\n",
      " [[70 75]\n",
      "  [80 85]\n",
      "  [90 95]]]\n",
      "y:\n",
      "[ 65  85 105 125 145 165 185]\n",
      "test_seq:\n",
      "[[[ 80  85]\n",
      "  [ 90  95]\n",
      "  [100 105]]]\n",
      "\n",
      "X.shape:(7, 3, 2), y.shape:(7,), test_seq.shape:(1, 3, 2)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                10600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,651\n",
      "Trainable params: 10,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:855.7574371619153\n",
      "yhat:[[205.53085]] \n",
      "-----------------------------\n",
      "-----------以下为 【多并行序列LSTM模型】 相关信息-----------------\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [40 45 85]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [ 50  55 105]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [ 60  65 125]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [ 70  75 145]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [ 80  85 165]\n",
      "[[ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]] [ 90  95 185]\n",
      "X:\n",
      "[[[ 10  15  25]\n",
      "  [ 20  25  45]\n",
      "  [ 30  35  65]]\n",
      "\n",
      " [[ 20  25  45]\n",
      "  [ 30  35  65]\n",
      "  [ 40  45  85]]\n",
      "\n",
      " [[ 30  35  65]\n",
      "  [ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 40  45  85]\n",
      "  [ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]\n",
      "  [ 70  75 145]]\n",
      "\n",
      " [[ 60  65 125]\n",
      "  [ 70  75 145]\n",
      "  [ 80  85 165]]]\n",
      "y:\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "test_seq:\n",
      "[[[ 70  75 145]\n",
      "  [ 80  85 165]\n",
      "  [ 90  95 185]]]\n",
      "\n",
      "X.shape:(6, 3, 3), y.shape:(6, 3), test_seq.shape:(1, 3, 3)\n",
      "\n",
      "\n",
      "train_acc:0.98333335 \n",
      "train_loss:326.7381566883183\n",
      "yhat:[[100.013954 105.58289  205.72787 ]] \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    orig_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    orig_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    train_seq = mock_seq(orig_seq1, orig_seq2)\n",
    "    \n",
    "    test_seq_multi = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "    test_seq_paral = np.array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "    \n",
    "    sw_width = 3\n",
    "    epochs_num = 500\n",
    "    verbose_set = 0\n",
    "    \n",
    "    print('-----------以下为 【多输入序列LSTM模型】 相关信息-----------------')\n",
    "    MultiInputLSTM = MultiInputModels(train_seq, test_seq_multi, sw_width, epochs_num, verbose_set)\n",
    "    MultiInputLSTM.split_sequence_multi_input()\n",
    "    MultiInputLSTM.vanilla_lstm()\n",
    "    print('-----------以下为 【多并行序列LSTM模型】 相关信息-----------------')\n",
    "    MultiInputLSTM = MultiInputModels(train_seq, test_seq_paral, sw_width, epochs_num, verbose_set)\n",
    "    MultiInputLSTM.split_sequence_parallel()\n",
    "    MultiInputLSTM.stacked_lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Bidirectional\n",
    "from tensorflow.keras.layers import TimeDistributed,RepeatVector\n",
    "        \n",
    "    \n",
    "class MultiStepModels:\n",
    "    '''\n",
    "    多时间步预测时间序列LSTM模型\n",
    "    '''\n",
    "    def __init__(self, train_seq, test_seq, sw_width, pred_length, features, epochs_num, verbose_set, flag=0): \n",
    "        '''\n",
    "        初始化变量和参数\n",
    "        '''\n",
    "        self.train_seq = train_seq\n",
    "        self.test_seq = test_seq\n",
    "        self.sw_width = sw_width\n",
    "        self.pred_length = pred_length\n",
    "        \n",
    "        self.features = features\n",
    "        \n",
    "        self.epochs_num = epochs_num\n",
    "        self.verbose_set = verbose_set\n",
    "        \n",
    "        self.flag = flag\n",
    "        \n",
    "        self.X, self.y = [], []     \n",
    "        \n",
    "    def split_sequence(self):\n",
    "        '''\n",
    "        该函数实现多输入序列数据的样本划分\n",
    "        '''\n",
    "        for i in range(len(self.train_seq)):\n",
    "            # 找到最后一个元素的索引，因为for循环中i从1开始，切片索引从0开始，切片区间前闭后开，所以不用减去1；\n",
    "            end_index = i + self.sw_width\n",
    "            # 找到需要预测指定时间步长的最后一个元素的索引；\n",
    "            out_end_index = end_index + self.pred_length\n",
    "            # 如果最后一个期望输出最后一个元素的索引大于序列中最后一个元素的索引则丢弃该样本；\n",
    "            # 这里len(self.sequence)没有减去1的原因是：保证最后一个元素的索引恰好等于序列数据索引时，能够截取到样本；\n",
    "            if out_end_index > len(self.train_seq) :\n",
    "                break\n",
    "                \n",
    "            # 实现以滑动步长为1（因为是for循环），窗口宽度为self.sw_width的滑动步长取值；\n",
    "            seq_x, seq_y = self.train_seq[i:end_index], self.train_seq[end_index:out_end_index]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            \n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "        self.X = self.X.reshape((self.X.shape[0], self.X.shape[1], self.features))\n",
    "        self.test_seq = self.test_seq.reshape((1, self.sw_width, self.features))\n",
    "\n",
    "        if self.flag == 1:\n",
    "            self.y = self.y.reshape((self.y.shape[0], self.y.shape[1], self.features))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "        \n",
    "        print('X:\\n{}\\ny:\\n{}\\ntest_seq:\\n{}\\n'.format(self.X, self.y, self.test_seq))\n",
    "        print('X.shape:{}, y.shape:{}, test_seq.shape:{}\\n'.format(self.X.shape, self.y.shape, self.test_seq.shape))\n",
    "        \n",
    "        return self.X, self.y, self.test_seq       \n",
    "\n",
    "    def stacked_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, activation='relu', return_sequences=True, \n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(LSTM(100, activation='relu'))\n",
    "        model.add(Dense(units=self.pred_length))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "\n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "\n",
    "    def encoder_decoder_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, activation='relu',\n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(RepeatVector(self.pred_length))\n",
    "        model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(1)))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------以下为 【向量输出 LSTM 模型】 相关信息------\n",
      "[[10]\n",
      " [20]\n",
      " [30]] [40 50]\n",
      "[[20]\n",
      " [30]\n",
      " [40]] [50 60]\n",
      "[[30]\n",
      " [40]\n",
      " [50]] [60 70]\n",
      "[[40]\n",
      " [50]\n",
      " [60]] [70 80]\n",
      "[[50]\n",
      " [60]\n",
      " [70]] [80 90]\n",
      "X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]]\n",
      "y:\n",
      "[[40 50]\n",
      " [50 60]\n",
      " [60 70]\n",
      " [70 80]\n",
      " [80 90]]\n",
      "test_seq:\n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]]\n",
      "\n",
      "X.shape:(5, 3, 1), y.shape:(5, 2), test_seq.shape:(1, 3, 1)\n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 3, 100)            40800     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 121,402\n",
      "Trainable params: 121,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:1.0 \n",
      "train_loss:752.8949569225312\n",
      "yhat:[[107.224014 119.64806 ]] \n",
      "-----------------------------\n",
      "-------以下为 【编码器-解码器 LSTM 模型】 相关信息------\n",
      "[[10]\n",
      " [20]\n",
      " [30]] [[40]\n",
      " [50]]\n",
      "[[20]\n",
      " [30]\n",
      " [40]] [[50]\n",
      " [60]]\n",
      "[[30]\n",
      " [40]\n",
      " [50]] [[60]\n",
      " [70]]\n",
      "[[40]\n",
      " [50]\n",
      " [60]] [[70]\n",
      " [80]]\n",
      "[[50]\n",
      " [60]\n",
      " [70]] [[80]\n",
      " [90]]\n",
      "X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]]\n",
      "y:\n",
      "[[[40]\n",
      "  [50]]\n",
      "\n",
      " [[50]\n",
      "  [60]]\n",
      "\n",
      " [[60]\n",
      "  [70]]\n",
      "\n",
      " [[70]\n",
      "  [80]]\n",
      "\n",
      " [[80]\n",
      "  [90]]]\n",
      "test_seq:\n",
      "[[[70]\n",
      "  [80]\n",
      "  [90]]]\n",
      "\n",
      "X.shape:(5, 3, 1), y.shape:(5, 2, 1), test_seq.shape:(1, 3, 1)\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 2, 100)            80400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 1)              101       \n",
      "=================================================================\n",
      "Total params: 121,301\n",
      "Trainable params: 121,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:694.8172243946791\n",
      "yhat:[[[102.96109 ]\n",
      "  [116.349144]]] \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    train_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    test_seq = np.array([70, 80, 90])\n",
    "    \n",
    "    sliding_window_width = 3\n",
    "    predict_length = 2\n",
    "    n_features = 1\n",
    "    \n",
    "    epochs_num = 100\n",
    "    verbose_set = 0\n",
    "    \n",
    "    print('-------以下为 【向量输出 LSTM 模型】 相关信息------')\n",
    "    MultiStepLSTM = MultiStepModels(train_seq, test_seq, sliding_window_width, predict_length, n_features, \n",
    "                                      epochs_num, verbose_set)\n",
    "    MultiStepLSTM.split_sequence()\n",
    "    MultiStepLSTM.stacked_lstm()\n",
    "    \n",
    "    print('-------以下为 【编码器-解码器 LSTM 模型】 相关信息------')\n",
    "    MultiStepLSTM = MultiStepModels(train_seq, test_seq, sliding_window_width, predict_length, n_features, \n",
    "                                      epochs_num, verbose_set, flag=1)\n",
    "    MultiStepLSTM.split_sequence()\n",
    "    MultiStepLSTM.encoder_decoder_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten\n",
    "from tensorflow.keras.layers import RepeatVector, TimeDistributed\n",
    "\n",
    "def mock_seq(seq1, seq2):\n",
    "    '''\n",
    "    构造虚拟序列数据\n",
    "    实现将多个单列序列数据构造成类似于实际数据的列表的格式\n",
    "    '''\n",
    "    seq1 = np.array(seq1)\n",
    "    seq2 = np.array(seq2)\n",
    "    seq3 = np.array([seq1[i]+seq2[i] for i in range(len(seq1))])\n",
    "    \n",
    "    seq1 = seq1.reshape((len(seq1), 1))\n",
    "    seq2 = seq2.reshape((len(seq2), 1))\n",
    "    seq3 = seq3.reshape((len(seq3), 1))\n",
    "    \n",
    "    # 对于二维数组，沿第二个维度堆叠，相当于列数增加；可以想象成往书架里一本一本的摆书\n",
    "    dataset = np.hstack((seq1, seq2, seq3))\n",
    "    \n",
    "    return dataset\n",
    "        \n",
    "    \n",
    "class MultivariateMultiStepModels:\n",
    "    '''\n",
    "    多变量多时间步预测LSTM模型\n",
    "    '''\n",
    "    def __init__(self, train_seq, test_seq, sw_width, pred_length, epochs_num, verbose_set): \n",
    "        '''\n",
    "        初始化变量和参数\n",
    "        '''\n",
    "        self.train_seq = train_seq\n",
    "        self.test_seq = test_seq\n",
    "        self.sw_width = sw_width\n",
    "        self.pred_length = pred_length\n",
    "        \n",
    "        self.epochs_num = epochs_num\n",
    "        self.verbose_set = verbose_set\n",
    "        \n",
    "        self.X, self.y = [], []     \n",
    "        \n",
    "    def split_sequence_multi_output(self):\n",
    "        '''\n",
    "        该函数实现多输入序列数据的样本划分\n",
    "        '''\n",
    "        for i in range(len(self.train_seq)):\n",
    "            # 找到最后一个元素的索引，因为for循环中i从1开始，切片索引从0开始，切片区间前闭后开，所以不用减去1；\n",
    "            end_index = i + self.sw_width\n",
    "            # 找到输出预测序列的最大索引，便于截取数据，因为i从1开始，切片索引从0开始，所以需要减去1；\n",
    "            out_end_index = end_index + self.pred_length - 1\n",
    "            # 如果最后一个滑动窗口中的最后一个元素的索引大于序列中最后一个元素的索引则丢弃该样本；\n",
    "            # 这里len(self.sequence)没有减去1的原因是：保证最后一个元素的索引恰好等于序列数据索引时，能够截取到样本；\n",
    "            if out_end_index > len(self.train_seq) :\n",
    "                break\n",
    "                \n",
    "            # 实现以滑动步长为1（因为是for循环），窗口宽度为self.sw_width的滑动步长取值；\n",
    "            # [i:end_index, :-1] 截取第i行到第end_index-1行、除最后一列之外的列的数据；\n",
    "            # [end_index-1:out_end_index, -1] 截取第end_index-1行到第out_end_index行、最后一列的数据；\n",
    "            seq_x, seq_y = self.train_seq[i:end_index, :-1], self.train_seq[end_index-1:out_end_index, -1]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            \n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "        self.features = self.X.shape[2]\n",
    "        self.test_seq = self.test_seq.reshape((1, self.sw_width, self.test_seq.shape[1]))\n",
    "\n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "        \n",
    "        print('X:\\n{}\\ny:\\n{}\\ntest_seq:\\n{}\\n'.format(self.X, self.y, self.test_seq))\n",
    "        print('X.shape:{}, y.shape:{}, test_seq.shape:{}\\n'.format(self.X.shape, self.y.shape, self.test_seq.shape))\n",
    "        \n",
    "        return self.X, self.y, self.features, self.test_seq\n",
    "    \n",
    "    def split_sequence_parallel(self):\n",
    "        '''\n",
    "        该函数实现多输入序列数据的样本划分\n",
    "        注意切片区间的选取！其实记住前闭后开区间就很好理解了。\n",
    "        '''\n",
    "        for i in range(len(self.train_seq)):\n",
    "            end_index = i + self.sw_width\n",
    "            out_end_index = end_index + self.pred_length\n",
    "            if out_end_index > len(self.train_seq) :\n",
    "                break\n",
    "                \n",
    "            # [i:end_index, :] 截取第i行到第end_index-1行、所有列的数据；\n",
    "            # [end_index:out_end_index, :] 截取第end_index行到第out_end_index行、所有列的数据；\n",
    "            seq_x, seq_y = self.train_seq[i:end_index, :], self.train_seq[end_index:out_end_index, :]\n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            \n",
    "        self.X, self.y = np.array(self.X), np.array(self.y)\n",
    "        self.features = self.X.shape[2]\n",
    "        self.test_seq = self.test_seq.reshape((1, self.sw_width, self.test_seq.shape[1]))\n",
    "\n",
    "        for i in range(len(self.X)):\n",
    "            print(self.X[i], self.y[i])\n",
    "        \n",
    "        print('X:\\n{}\\ny:\\n{}\\ntest_seq:\\n{}\\n'.format(self.X, self.y, self.test_seq))\n",
    "        print('X.shape:{}, y.shape:{}, test_seq.shape:{}\\n'.format(self.X.shape, self.y.shape, self.test_seq.shape))\n",
    "        \n",
    "        return self.X, self.y, self.features, self.test_seq    \n",
    "    \n",
    "    def stacked_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(100, activation='relu', return_sequences=True, \n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(LSTM(100, activation='relu'))\n",
    "        model.add(Dense(units=self.pred_length))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        \n",
    "    def encoder_decoder_lstm(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(200, activation='relu',\n",
    "                       input_shape=(self.sw_width, self.features)))\n",
    "        model.add(RepeatVector(self.pred_length))\n",
    "        model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(self.features)))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        history = model.fit(self.X, self.y, epochs=self.epochs_num, verbose=self.verbose_set)\n",
    "        print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))\n",
    "        print('yhat:%s'%(model.predict(self.test_seq)),'\\n-----------------------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------以下为 【多输入多时间步预测输出 LSTM 模型】 相关信息------\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] [65 85]\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] [ 85 105]\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] [105 125]\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] [125 145]\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] [145 165]\n",
      "[[60 65]\n",
      " [70 75]\n",
      " [80 85]] [165 185]\n",
      "X:\n",
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]\n",
      "\n",
      " [[20 25]\n",
      "  [30 35]\n",
      "  [40 45]]\n",
      "\n",
      " [[30 35]\n",
      "  [40 45]\n",
      "  [50 55]]\n",
      "\n",
      " [[40 45]\n",
      "  [50 55]\n",
      "  [60 65]]\n",
      "\n",
      " [[50 55]\n",
      "  [60 65]\n",
      "  [70 75]]\n",
      "\n",
      " [[60 65]\n",
      "  [70 75]\n",
      "  [80 85]]]\n",
      "y:\n",
      "[[ 65  85]\n",
      " [ 85 105]\n",
      " [105 125]\n",
      " [125 145]\n",
      " [145 165]\n",
      " [165 185]]\n",
      "test_seq:\n",
      "[[[ 80  85]\n",
      "  [ 90  95]\n",
      "  [100 105]]]\n",
      "\n",
      "X.shape:(6, 3, 2), y.shape:(6, 2), test_seq.shape:(1, 3, 2)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 3, 100)            41200     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 121,802\n",
      "Trainable params: 121,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:0.8641666 \n",
      "train_loss:1499.5305340608954\n",
      "yhat:[[207.57896 231.91385]] \n",
      "-----------------------------\n",
      "-------以下为 【并行输入多时间步预测输出 LSTM 模型】 相关信息------\n",
      "[[10 15 25]\n",
      " [20 25 45]\n",
      " [30 35 65]] [[ 40  45  85]\n",
      " [ 50  55 105]]\n",
      "[[20 25 45]\n",
      " [30 35 65]\n",
      " [40 45 85]] [[ 50  55 105]\n",
      " [ 60  65 125]]\n",
      "[[ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]] [[ 60  65 125]\n",
      " [ 70  75 145]]\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]] [[ 70  75 145]\n",
      " [ 80  85 165]]\n",
      "[[ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]] [[ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "X:\n",
      "[[[ 10  15  25]\n",
      "  [ 20  25  45]\n",
      "  [ 30  35  65]]\n",
      "\n",
      " [[ 20  25  45]\n",
      "  [ 30  35  65]\n",
      "  [ 40  45  85]]\n",
      "\n",
      " [[ 30  35  65]\n",
      "  [ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 40  45  85]\n",
      "  [ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]\n",
      "  [ 70  75 145]]]\n",
      "y:\n",
      "[[[ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 60  65 125]\n",
      "  [ 70  75 145]]\n",
      "\n",
      " [[ 70  75 145]\n",
      "  [ 80  85 165]]\n",
      "\n",
      " [[ 80  85 165]\n",
      "  [ 90  95 185]]]\n",
      "test_seq:\n",
      "[[[ 60  65 125]\n",
      "  [ 70  75 145]\n",
      "  [ 80  85 165]]]\n",
      "\n",
      "X.shape:(5, 3, 3), y.shape:(5, 2, 3), test_seq.shape:(1, 3, 3)\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 200)               163200    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 2, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 2, 200)            320800    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 2, 3)              603       \n",
      "=================================================================\n",
      "Total params: 484,603\n",
      "Trainable params: 484,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "train_acc:1.0 \n",
      "train_loss:499.6571237371396\n",
      "yhat:[[[ 90.40701  96.32832 186.49251]\n",
      "  [100.81339 104.66335 205.89095]]] \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    orig_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    orig_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    train_seq = mock_seq(orig_seq1, orig_seq2)\n",
    "    \n",
    "    test_seq_multi = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "    test_seq_paral = np.array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "    \n",
    "    sliding_window_width = 3\n",
    "    predict_length = 2\n",
    "    epochs_num = 200\n",
    "    verbose_set = 0\n",
    "    \n",
    "    print('-------以下为 【多输入多时间步预测输出 LSTM 模型】 相关信息------')\n",
    "    MultivariateMultiStepLSTM = MultivariateMultiStepModels(train_seq, test_seq_multi, sliding_window_width, predict_length,\n",
    "                                                            epochs_num, verbose_set)\n",
    "    MultivariateMultiStepLSTM.split_sequence_multi_output()\n",
    "    MultivariateMultiStepLSTM.stacked_lstm()\n",
    "    \n",
    "    print('-------以下为 【并行输入多时间步预测输出 LSTM 模型】 相关信息------')\n",
    "    MultivariateMultiStepLSTM = MultivariateMultiStepModels(train_seq, test_seq_paral, sliding_window_width, predict_length,\n",
    "                                                            epochs_num, verbose_set)\n",
    "    MultivariateMultiStepLSTM.split_sequence_parallel()\n",
    "    MultivariateMultiStepLSTM.encoder_decoder_lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
