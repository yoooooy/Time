{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_sequence:\n",
      "X:\n",
      "[[10 20 30]\n",
      " [20 30 40]\n",
      " [30 40 50]\n",
      " [40 50 60]\n",
      " [50 60 70]\n",
      " [60 70 80]]\n",
      "y:\n",
      "[40 50 60 70 80 90]\n",
      "\n",
      "X_shape:(6, 3),y_shape:(6,)\n",
      "\n",
      "train_X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]\n",
      "\n",
      " [[60]\n",
      "  [70]\n",
      "  [80]]]\n",
      "train_y:\n",
      "[40 50 60 70 80 90]\n",
      "\n",
      "trainX.shape:(6, 3, 1),triany_shape:(6,)\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,493\n",
      "Trainable params: 3,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[101.824524]]\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:83.09048912930488\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "# 该该函数将序列数据分割成样本\n",
    "def split_sequence(sequence, sw_width, n_features):\n",
    "    '''\n",
    "    这个简单的示例，通过for循环实现有重叠截取数据，滑动步长为1，滑动窗口宽度为sw_width。\n",
    "    以后的文章，会介绍使用yield方法来实现特定滑动步长的滑动窗口的实例。\n",
    "    '''\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        # 获取单个样本中最后一个元素的索引，因为python切片前闭后开，索引从0开始，所以不需要-1\n",
    "        end_element_index = i + sw_width\n",
    "        # 如果样本最后一个元素的索引超过了序列索引的最大长度，说明不满足样本元素个数，则这个样本丢弃\n",
    "        if end_element_index > len(sequence) - 1:\n",
    "            break\n",
    "        # 通过切片实现步长为1的滑动窗口截取数据组成样本的效果\n",
    "        seq_x, seq_y = sequence[i:end_element_index], sequence[end_element_index]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        process_X, process_y = np.array(X), np.array(y)\n",
    "        process_X = process_X.reshape((process_X.shape[0], process_X.shape[1], n_features))\n",
    "    \n",
    "    print('split_sequence:\\nX:\\n{}\\ny:\\n{}\\n'.format(np.array(X), np.array(y)))\n",
    "    print('X_shape:{},y_shape:{}\\n'.format(np.array(X).shape, np.array(y).shape))\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    return process_X, process_y\n",
    "\n",
    "    \n",
    "def oned_cnn_model(sw_width, n_features, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 对于一维卷积来说，data_format='channels_last'是默认配置，该API的规则如下：\n",
    "    # 输入形状为：(batch, steps, channels)；输出形状为：(batch, new_steps, filters)，padding和strides的变化会导致new_steps变化\n",
    "    # 如果设置为data_format = 'channels_first'，则要求输入形状为： (batch, channels, steps).\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(sw_width, n_features)))\n",
    "    \n",
    "    # 对于一维池化层来说，data_format='channels_last'是默认配置，该API的规则如下：\n",
    "    # 3D 张量的输入形状为: (batch_size, steps, features)；输出3D张量的形状为：(batch_size, downsampled_steps, features)\n",
    "    # 如果设置为data_format = 'channels_first'，则要求输入形状为：(batch_size, features, steps)\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    # data_format参数的作用是在将模型从一种数据格式切换到另一种数据格式时保留权重顺序。默认为channels_last。\n",
    "    # 如果设置为channels_last，那么数据输入形状应为：（batch，…，channels）；如果设置为channels_first，那么数据输入形状应该为（batch，channels，…）\n",
    "    # 输出为（batch, 之后参数尺寸的乘积）\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense执行以下操作：output=activation（dot（input，kernel）+bias），\n",
    "    # 其中,activation是激活函数，kernel是由层创建的权重矩阵，bias是由层创建的偏移向量（仅当use_bias为True时适用）。\n",
    "    # 2D 输入：(batch_size, input_dim)；对应 2D 输出：(batch_size, units)\n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    # 因为要预测下一个时间步的值，因此units设置为1\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # 配置模型\n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    # X为输入数据，y为数据标签；batch_size：每次梯度更新的样本数，默认为32。\n",
    "    # verbose: 0,1,2. 0=训练过程无输出，1=显示训练过程进度条，2=每训练一个epoch打印一次信息\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    sw_width = 3\n",
    "    n_features = 1\n",
    "    epoch_num = 1000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y = split_sequence(train_seq, sw_width, n_features)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([70, 80, 90])\n",
    "    x_input = x_input.reshape((1, sw_width, n_features))\n",
    "    \n",
    "    model, history = oned_cnn_model(sw_width, n_features, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "    \n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      " [[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "train_X:\n",
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]\n",
      "\n",
      " [[20 25]\n",
      "  [30 35]\n",
      "  [40 45]]\n",
      "\n",
      " [[30 35]\n",
      "  [40 45]\n",
      "  [50 55]]\n",
      "\n",
      " [[40 45]\n",
      "  [50 55]\n",
      "  [60 65]]\n",
      "\n",
      " [[50 55]\n",
      "  [60 65]\n",
      "  [70 75]]\n",
      "\n",
      " [[60 65]\n",
      "  [70 75]\n",
      "  [80 85]]\n",
      "\n",
      " [[70 75]\n",
      "  [80 85]\n",
      "  [90 95]]]\n",
      "train_y:\n",
      "[ 65  85 105 125 145 165 185]\n",
      "\n",
      "train_X.shape:(7, 3, 2),trian_y.shape:(7,)\n",
      "\n",
      "n_features: 2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 2, 64)             320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,621\n",
      "Trainable params: 3,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[205.84216]]\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:290.3450777206163\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "def split_sequences(first_seq, secend_seq, sw_width):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "    input_seq1 = np.array(first_seq).reshape(len(first_seq), 1)\n",
    "    input_seq2 = np.array(secend_seq).reshape(len(secend_seq), 1)\n",
    "    out_seq = np.array([first_seq[i]+secend_seq[i] for i in range(len(first_seq))])\n",
    "    out_seq = out_seq.reshape(len(out_seq), 1)\n",
    "    \n",
    "    dataset = np.hstack((input_seq1, input_seq2, out_seq))\n",
    "    print('dataset:\\n',dataset)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        # 切片索引从0开始，区间为前闭后开，所以不用减去1\n",
    "        end_element_index = i + sw_width\n",
    "        # 同样的道理，这里考虑最后一个样本正好取到最后一行的数据，那么索引不能减1，如果减去1的话最后一个样本就取不到了。\n",
    "        if end_element_index > len(dataset):\n",
    "            break\n",
    "        \n",
    "        # 该语句实现步长为1的滑动窗口截取数据功能；\n",
    "        # 以下切片中，:-1 表示取除最后一列的其他列数据；-1表示取最后一列的数据\n",
    "        seq_x, seq_y = dataset[i:end_element_index, :-1], dataset[end_element_index-1, -1]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        process_X, process_y = np.array(X), np.array(y)\n",
    "    \n",
    "    n_features = process_X.shape[2]\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    print('n_features:',n_features)\n",
    "    return process_X, process_y, n_features\n",
    "\n",
    "    \n",
    "def oned_cnn_model(sw_width, n_features, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(sw_width, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    train_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    sw_width = 3\n",
    "\n",
    "    epoch_num = 1000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y, n_features = split_sequences(train_seq1, train_seq2, sw_width)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "    x_input = x_input.reshape((1, sw_width, n_features))\n",
    "    \n",
    "    model, history = oned_cnn_model(sw_width, n_features, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "    \n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      " [[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "train_X:\n",
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]\n",
      "\n",
      " [[20 25]\n",
      "  [30 35]\n",
      "  [40 45]]\n",
      "\n",
      " [[30 35]\n",
      "  [40 45]\n",
      "  [50 55]]\n",
      "\n",
      " [[40 45]\n",
      "  [50 55]\n",
      "  [60 65]]\n",
      "\n",
      " [[50 55]\n",
      "  [60 65]\n",
      "  [70 75]]\n",
      "\n",
      " [[60 65]\n",
      "  [70 75]\n",
      "  [80 85]]\n",
      "\n",
      " [[70 75]\n",
      "  [80 85]\n",
      "  [90 95]]]\n",
      "train_y:\n",
      "[ 65  85 105 125 145 165 185]\n",
      "\n",
      "train_X.shape:(7, 3, 2),trian_y.shape:(7,)\n",
      "\n",
      "X1.shape:(7, 3, 1),X2.shape:(7, 3, 1)\n",
      "\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 3, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 3, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 2, 64)        192         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 2, 64)        192         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 64)        0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 1, 64)        0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 64)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 64)           0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128)          0           flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 50)           6450        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            51          dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,885\n",
      "Trainable params: 6,885\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[205.66142]]\n",
      "\n",
      "train_acc:0.0 \n",
      "train_loss:201.12432714579907\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Input, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def split_sequences2(first_seq, secend_seq, sw_width, n_features):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "    input_seq1 = np.array(first_seq).reshape(len(first_seq), 1)\n",
    "    input_seq2 = np.array(secend_seq).reshape(len(secend_seq), 1)\n",
    "    out_seq = np.array([first_seq[i]+secend_seq[i] for i in range(len(first_seq))])\n",
    "    out_seq = out_seq.reshape(len(out_seq), 1)\n",
    "    \n",
    "    dataset = np.hstack((input_seq1, input_seq2, out_seq))\n",
    "    print('dataset:\\n',dataset)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        # 切片索引从0开始，区间为前闭后开，所以不用减去1\n",
    "        end_element_index = i + sw_width\n",
    "        # 同样的道理，这里考虑最后一个样本正好取到最后一行的数据，那么索引不能减1，如果减去1的话最后一个样本就取不到了。\n",
    "        if end_element_index > len(dataset):\n",
    "            break\n",
    "        \n",
    "        # 该语句实现步长为1的滑动窗口截取数据功能；\n",
    "        # 以下切片中，:-1 表示取除最后一列的其他列数据；-1表示取最后一列的数据\n",
    "        seq_x, seq_y = dataset[i:end_element_index, :-1], dataset[end_element_index-1, -1]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        process_X, process_y = np.array(X), np.array(y)\n",
    "    \n",
    "    # [:,:,0]表示三维数组前两个维度的数据全取，第三个维度取第一个数据，可以想象成一摞饼干，取了一块。\n",
    "    # 本例中 process_X的shape为（7,3,2），所以下式就很好理解了，\n",
    "    X1 = process_X[:,:,0].reshape(process_X.shape[0], process_X.shape[1], n_features)\n",
    "    X2 = process_X[:,:,1].reshape(process_X.shape[0], process_X.shape[1], n_features)\n",
    "\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    print('X1.shape:{},X2.shape:{}\\n'.format(X1.shape, X2.shape))\n",
    "    \n",
    "    return X1, X2, process_y\n",
    "\n",
    "    \n",
    "def oned_cnn_model(n_steps, n_features, X_1, X_2, y, x1, x2, epoch_num, verbose_set):\n",
    "    \n",
    "    visible1 = Input(shape=(n_steps, n_features))\n",
    "    cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible1)\n",
    "    cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
    "    cnn1 = Flatten()(cnn1)\n",
    "\n",
    "    visible2 = Input(shape=(n_steps, n_features))\n",
    "    cnn2 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible2)\n",
    "    cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
    "    cnn2 = Flatten()(cnn2)\n",
    "    \n",
    "    merge = concatenate([cnn1, cnn2])\n",
    "    dense = Dense(50, activation='relu')(merge)\n",
    "    output = Dense(1)(dense)\n",
    "\n",
    "    model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    plot_model(model, to_file='multi_head_cnn_model.png', show_shapes=True, show_layer_names=True, rankdir='TB', dpi=200)\n",
    "    \n",
    "    history = model.fit([X_1, X_2], y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "\n",
    "    yhat = model.predict([x1,x2], verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    train_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    sw_width = 3\n",
    "    n_features = 1\n",
    "    epoch_num = 1000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X1, train_X2, train_y = split_sequences2(train_seq1, train_seq2, sw_width, n_features)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
    "    x_1 = x_input[:, 0].reshape((1, sw_width, n_features))\n",
    "    x_2 = x_input[:, 1].reshape((1, sw_width, n_features))\n",
    "    \n",
    "    model, history = oned_cnn_model(sw_width, n_features, train_X1, train_X2, train_y, x_1, x_2, epoch_num, verbose_set)\n",
    "\n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      " [[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "train_X:\n",
      "[[[ 10  15  25]\n",
      "  [ 20  25  45]\n",
      "  [ 30  35  65]]\n",
      "\n",
      " [[ 20  25  45]\n",
      "  [ 30  35  65]\n",
      "  [ 40  45  85]]\n",
      "\n",
      " [[ 30  35  65]\n",
      "  [ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 40  45  85]\n",
      "  [ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]\n",
      "  [ 70  75 145]]\n",
      "\n",
      " [[ 60  65 125]\n",
      "  [ 70  75 145]\n",
      "  [ 80  85 165]]]\n",
      "train_y:\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "\n",
      "train_X.shape:(6, 3, 3),trian_y.shape:(6, 3)\n",
      "\n",
      "n_features: 3\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 2, 64)             448       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 3,851\n",
      "Trainable params: 3,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[100.58862 106.20969 207.11055]]\n",
      "\n",
      "train_acc:0.9979444 \n",
      "train_loss:36.841995810692595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "def split_sequences(first_seq, secend_seq, sw_width):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "    input_seq1 = np.array(first_seq).reshape(len(first_seq), 1)\n",
    "    input_seq2 = np.array(secend_seq).reshape(len(secend_seq), 1)\n",
    "    out_seq = np.array([first_seq[i]+secend_seq[i] for i in range(len(first_seq))])\n",
    "    out_seq = out_seq.reshape(len(out_seq), 1)\n",
    "    \n",
    "    dataset = np.hstack((input_seq1, input_seq2, out_seq))\n",
    "    print('dataset:\\n',dataset)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        end_element_index = i + sw_width\n",
    "        if end_element_index > len(dataset) - 1:\n",
    "            break\n",
    "        \n",
    "        # 该语句实现步长为1的滑动窗口截取数据功能；\n",
    "        seq_x, seq_y = dataset[i:end_element_index, :], dataset[end_element_index, :]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        process_X, process_y = np.array(X), np.array(y)\n",
    "    \n",
    "    n_features = process_X.shape[2]\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    print('n_features:',n_features)\n",
    "    return process_X, process_y, n_features\n",
    "\n",
    "    \n",
    "def oned_cnn_model(sw_width, n_features, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(sw_width, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    model.add(Dense(units=n_features))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    train_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    sw_width = 3\n",
    "\n",
    "    epoch_num = 3000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y, n_features = split_sequences(train_seq1, train_seq2, sw_width)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "    x_input = x_input.reshape((1, sw_width, n_features))\n",
    "    \n",
    "    model, history = oned_cnn_model(sw_width, n_features, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "    \n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      " [[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "train_X:\n",
      "[[[ 10  15  25]\n",
      "  [ 20  25  45]\n",
      "  [ 30  35  65]]\n",
      "\n",
      " [[ 20  25  45]\n",
      "  [ 30  35  65]\n",
      "  [ 40  45  85]]\n",
      "\n",
      " [[ 30  35  65]\n",
      "  [ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 40  45  85]\n",
      "  [ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]\n",
      "  [ 70  75 145]]\n",
      "\n",
      " [[ 60  65 125]\n",
      "  [ 70  75 145]\n",
      "  [ 80  85 165]]]\n",
      "train_y:\n",
      "[[ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "\n",
      "train_X.shape:(6, 3, 3),trian_y.shape:(6, 3)\n",
      "\n",
      "n_features: 3\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 3, 3)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2, 64)        448         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 64)        0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 50)           3250        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            51          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,851\n",
      "Trainable params: 3,851\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [array([[101.1264]], dtype=float32), array([[106.274635]], dtype=float32), array([[207.64928]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Input, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def split_sequences(first_seq, secend_seq, sw_width):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "    input_seq1 = np.array(first_seq).reshape(len(first_seq), 1)\n",
    "    input_seq2 = np.array(secend_seq).reshape(len(secend_seq), 1)\n",
    "    out_seq = np.array([first_seq[i]+secend_seq[i] for i in range(len(first_seq))])\n",
    "    out_seq = out_seq.reshape(len(out_seq), 1)\n",
    "    \n",
    "    dataset = np.hstack((input_seq1, input_seq2, out_seq))\n",
    "    print('dataset:\\n',dataset)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        end_element_index = i + sw_width\n",
    "        if end_element_index > len(dataset) - 1:\n",
    "            break\n",
    "        \n",
    "        # 该语句实现步长为1的滑动窗口截取数据功能；\n",
    "        seq_x, seq_y = dataset[i:end_element_index, :], dataset[end_element_index, :]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        process_X, process_y = np.array(X), np.array(y)\n",
    "    \n",
    "    n_features = process_X.shape[2]\n",
    "    y1 = process_y[:, 0].reshape((process_y.shape[0], 1))\n",
    "    y2 = process_y[:, 1].reshape((process_y.shape[0], 1))\n",
    "    y3 = process_y[:, 2].reshape((process_y.shape[0], 1))\n",
    "    \n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    print('n_features:',n_features)\n",
    "    return process_X, process_y, n_features, y1, y2, y3\n",
    "\n",
    "    \n",
    "def oned_cnn_model(n_steps, n_features, X, y, test_X, epoch_num, verbose_set):\n",
    "    visible = Input(shape=(n_steps, n_features))\n",
    "    cnn = Conv1D(filters=64, kernel_size=2, activation='relu')(visible)\n",
    "    cnn = MaxPooling1D(pool_size=2)(cnn)\n",
    "    cnn = Flatten()(cnn)\n",
    "    cnn = Dense(50, activation='relu')(cnn)\n",
    "    \n",
    "    output1 = Dense(1)(cnn)\n",
    "    output2 = Dense(1)(cnn)\n",
    "    output3 = Dense(1)(cnn)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=[output1, output2, output3])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    plot_model(model, to_file='vector_output_cnn_model.png', show_shapes=True, show_layer_names=True, rankdir='TB', dpi=200)\n",
    "\n",
    "    model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    train_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    sw_width = 3\n",
    "\n",
    "    epoch_num = 2000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y, n_features, y1, y2, y3 = split_sequences(train_seq1, train_seq2, sw_width)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "    x_input = x_input.reshape((1, sw_width, n_features))\n",
    "    \n",
    "    model = oned_cnn_model(sw_width, n_features, train_X, [y1, y2, y3], x_input, epoch_num, verbose_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss__ = np.array([[101.32952]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.32952"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss__[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X:\n",
      "[[[10]\n",
      "  [20]\n",
      "  [30]]\n",
      "\n",
      " [[20]\n",
      "  [30]\n",
      "  [40]]\n",
      "\n",
      " [[30]\n",
      "  [40]\n",
      "  [50]]\n",
      "\n",
      " [[40]\n",
      "  [50]\n",
      "  [60]]\n",
      "\n",
      " [[50]\n",
      "  [60]\n",
      "  [70]]]\n",
      "train_y:\n",
      "[[40 50]\n",
      " [50 60]\n",
      " [60 70]\n",
      " [70 80]\n",
      " [80 90]]\n",
      "\n",
      "train_X.shape:(5, 3, 1),trian_y.shape:(5, 2)\n",
      "\n",
      "n_features: 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 2, 64)             192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 3,544\n",
      "Trainable params: 3,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[102.96412 114.83157]]\n",
      "\n",
      "train_acc:1.0 \n",
      "train_loss:74.88895527674454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "def split_sequences(sequence, n_steps_in, n_steps_out, n_features):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "       \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(X, y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(X.shape, y.shape))\n",
    "    print('n_features:',n_features)\n",
    "    return X, y\n",
    "\n",
    "    \n",
    "def oned_cnn_model(steps_in, n_features, steps_out, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(steps_in, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    model.add(Dense(units=steps_out))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    n_steps_in, n_steps_out = 3, 2\n",
    "    n_features = 1\n",
    "    epoch_num = 2000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y = split_sequences(train_seq1, n_steps_in, n_steps_out, n_features)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([70, 80, 90])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    \n",
    "    model, history = oned_cnn_model(n_steps_in, n_features, n_steps_out, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "    \n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      " [[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "train_X:\n",
      "[[[10 15]\n",
      "  [20 25]\n",
      "  [30 35]]\n",
      "\n",
      " [[20 25]\n",
      "  [30 35]\n",
      "  [40 45]]\n",
      "\n",
      " [[30 35]\n",
      "  [40 45]\n",
      "  [50 55]]\n",
      "\n",
      " [[40 45]\n",
      "  [50 55]\n",
      "  [60 65]]\n",
      "\n",
      " [[50 55]\n",
      "  [60 65]\n",
      "  [70 75]]\n",
      "\n",
      " [[60 65]\n",
      "  [70 75]\n",
      "  [80 85]]]\n",
      "train_y:\n",
      "[[ 65  85]\n",
      " [ 85 105]\n",
      " [105 125]\n",
      " [125 145]\n",
      " [145 165]\n",
      " [165 185]]\n",
      "\n",
      "train_X.shape:(6, 3, 2),trian_y.shape:(6, 2)\n",
      "\n",
      "n_features: 2\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 2, 64)             320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 3,672\n",
      "Trainable params: 3,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[187.56087 217.18515]]\n",
      "\n",
      "train_acc:0.921 \n",
      "train_loss:440.7402523803711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "def split_sequences(first_seq, secend_seq, steps_in, steps_out):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "    input_seq1 = np.array(first_seq).reshape(len(first_seq), 1)\n",
    "    input_seq2 = np.array(secend_seq).reshape(len(secend_seq), 1)\n",
    "    out_seq = np.array([first_seq[i]+secend_seq[i] for i in range(len(first_seq))])\n",
    "    out_seq = out_seq.reshape(len(out_seq), 1)\n",
    "    \n",
    "    dataset = np.hstack((input_seq1, input_seq2, out_seq))\n",
    "    print('dataset:\\n',dataset)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        end_element_index = i + steps_in\n",
    "        out_end_index = end_element_index + steps_out-1\n",
    "        \n",
    "        if end_element_index > len(dataset)-1:\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = dataset[i:end_element_index, :-1], dataset[end_element_index-1:out_end_index, -1]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    process_X, process_y = np.array(X), np.array(y)\n",
    "    \n",
    "    n_features = process_X.shape[2]\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(process_X, process_y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(process_X.shape, process_y.shape))\n",
    "    print('n_features:',n_features)\n",
    "    return process_X, process_y, n_features\n",
    "\n",
    "    \n",
    "def oned_cnn_model(step_in, step_out, n_features, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(step_in, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    model.add(Dense(units=step_out))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    train_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "    epoch_num = 1000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y, n_feature = split_sequences(train_seq1, train_seq2, n_steps_in, n_steps_out)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([[70, 75], [80, 85], [90, 95]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_feature))\n",
    "    \n",
    "    model, history = oned_cnn_model(n_steps_in, n_steps_out, n_feature, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "    \n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      " [[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "train_X:\n",
      "[[[ 10  15  25]\n",
      "  [ 20  25  45]\n",
      "  [ 30  35  65]]\n",
      "\n",
      " [[ 20  25  45]\n",
      "  [ 30  35  65]\n",
      "  [ 40  45  85]]\n",
      "\n",
      " [[ 30  35  65]\n",
      "  [ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 40  45  85]\n",
      "  [ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]\n",
      "  [ 70  75 145]]]\n",
      "train_y:\n",
      "[[ 40  45  85  50  55 105]\n",
      " [ 50  55 105  60  65 125]\n",
      " [ 60  65 125  70  75 145]\n",
      " [ 70  75 145  80  85 165]\n",
      " [ 80  85 165  90  95 185]]\n",
      "\n",
      "train_X.shape:(5, 3, 3),trian_y.shape:(5, 6)\n",
      "\n",
      "n_features: 3\n",
      "n_output: 6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 2, 64)             448       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 4,004\n",
      "Trainable params: 4,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      " None\n",
      "\n",
      "yhat: [[ 90.29059   95.43707  185.55986  100.08475  105.629974 205.868   ]]\n",
      "\n",
      "train_acc:0.9925143 \n",
      "train_loss:33.875467088381\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "def split_sequences(first_seq, secend_seq, steps_in, steps_out):\n",
    "    '''\n",
    "    该函数将序列数据分割成样本\n",
    "    '''\n",
    "    input_seq1 = np.array(first_seq).reshape(len(first_seq), 1)\n",
    "    input_seq2 = np.array(secend_seq).reshape(len(secend_seq), 1)\n",
    "    out_seq = np.array([first_seq[i]+secend_seq[i] for i in range(len(first_seq))])\n",
    "    out_seq = out_seq.reshape(len(out_seq), 1)\n",
    "    \n",
    "    dataset = np.hstack((input_seq1, input_seq2, out_seq))\n",
    "    print('dataset:\\n',dataset)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        end_element_index = i + steps_in\n",
    "        out_end_index = end_element_index + steps_out\n",
    "        \n",
    "        if out_end_index > len(dataset):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = dataset[i:end_element_index, :], dataset[end_element_index:out_end_index, :]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "    \n",
    "    n_features = X.shape[2]\n",
    "    print('train_X:\\n{}\\ntrain_y:\\n{}\\n'.format(X, y))\n",
    "    print('train_X.shape:{},trian_y.shape:{}\\n'.format(X.shape, y.shape))\n",
    "    print('n_features:',n_features)\n",
    "    print('n_output:',n_output)\n",
    "    return X, y, n_features, n_output\n",
    "\n",
    "    \n",
    "def oned_cnn_model(step_in, step_out, n_features, n_output, X, y, test_X, epoch_num, verbose_set):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu',\n",
    "                     strides=1, padding='valid', data_format='channels_last',\n",
    "                     input_shape=(step_in, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2, strides=None, padding='valid', \n",
    "                           data_format='channels_last')) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=50, activation='relu',\n",
    "                use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',))\n",
    "    \n",
    "    model.add(Dense(units=n_output))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse',\n",
    "                 metrics=['accuracy'], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "    print('\\n',model.summary())\n",
    "    \n",
    "    history = model.fit(X, y, batch_size=32, epochs=epoch_num, verbose=verbose_set)\n",
    "    \n",
    "    \n",
    "    yhat = model.predict(test_X, verbose=0)\n",
    "    print('\\nyhat:', yhat)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_seq1 = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    train_seq2 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "    n_steps_in, n_steps_out = 3, 2\n",
    "\n",
    "    epoch_num = 7000\n",
    "    verbose_set = 0\n",
    "    \n",
    "    train_X, train_y, n_feature, n_output = split_sequences(train_seq1, train_seq2, n_steps_in, n_steps_out)\n",
    "\n",
    "    # 预测\n",
    "    x_input = np.array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_feature))\n",
    "    \n",
    "    model, history = oned_cnn_model(n_steps_in, n_steps_out, n_feature, n_output, train_X, train_y, x_input, epoch_num, verbose_set)\n",
    "    \n",
    "    print('\\ntrain_acc:%s'%np.mean(history.history['accuracy']), '\\ntrain_loss:%s'%np.mean(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
